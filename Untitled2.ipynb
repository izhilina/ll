{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/izhilina/ll/blob/master/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cloud-tpu-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "rUYi2IuXRzap",
        "outputId": "75ec5742-49d0-4b83-e433-e5026fd4532d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: uritemplate, google-api-core, google-api-python-client, cloud-tpu-client\n",
            "  Attempting uninstall: uritemplate\n",
            "    Found existing installation: uritemplate 4.1.1\n",
            "    Uninstalling uritemplate-4.1.1:\n",
            "      Successfully uninstalled uritemplate-4.1.1\n",
            "  Attempting uninstall: google-api-core\n",
            "    Found existing installation: google-api-core 2.11.1\n",
            "    Uninstalling google-api-core-2.11.1:\n",
            "      Successfully uninstalled google-api-core-2.11.1\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 2.84.0\n",
            "    Uninstalling google-api-python-client-2.84.0:\n",
            "      Successfully uninstalled google-api-python-client-2.84.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pydrive2 1.6.3 requires google-api-python-client>=1.12.5, but you have google-api-python-client 1.8.0 which is incompatible.\n",
            "earthengine-api 0.1.381 requires google-api-python-client>=1.12.1, but you have google-api-python-client 1.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cloud-tpu-client-0.10 google-api-core-1.34.0 google-api-python-client-1.8.0 uritemplate-3.0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ],
      "metadata": {
        "id": "il3cgZIsR7Xz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['COLAB_TPU_ADDR']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "J1jVPYxmSaGW",
        "outputId": "17f926ec-96dc-4009-8eb3-1b052132d88a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'10.14.228.154:8470'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/huggingface/diffusers\n",
        "# !cd diffusers\n",
        "!pip install diffusers/.\n",
        "!pip install -r diffusers/examples/text_to_image/requirements.txt\n",
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRCConKSSAKx",
        "outputId": "1c870640-44ae-4445-9dd8-4fed99c6f5c2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'diffusers'...\n",
            "remote: Enumerating objects: 47880, done.\u001b[K\n",
            "remote: Counting objects: 100% (1530/1530), done.\u001b[K\n",
            "remote: Compressing objects: 100% (644/644), done.\u001b[K\n",
            "remote: Total 47880 (delta 1035), reused 1175 (delta 786), pack-reused 46350\u001b[K\n",
            "Receiving objects: 100% (47880/47880), 31.78 MiB | 16.19 MiB/s, done.\n",
            "Resolving deltas: 100% (35304/35304), done.\n",
            "Processing ./diffusers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0.dev0) (6.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0.dev0) (0.19.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0.dev0) (1.23.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0.dev0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0.dev0) (0.4.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0.dev0) (9.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0.dev0) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0.dev0) (23.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.25.0.dev0) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.25.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.25.0.dev0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.25.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.25.0.dev0) (2023.11.17)\n",
            "Building wheels for collected packages: diffusers\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.25.0.dev0-py3-none-any.whl size=1812873 sha256=d5d3c09faabe0c0bcd8030a7cdd93844e963e421f443a8f9dfa066bdeb65ae57\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-my7_q60d/wheels/95/c5/3b/e1b4269f8a2584de57e75f949a185b48fc4144e9a91fc9965a\n",
            "Successfully built diffusers\n",
            "Installing collected packages: diffusers\n",
            "Successfully installed diffusers-0.25.0.dev0\n",
            "Collecting accelerate>=0.16.0 (from -r diffusers/examples/text_to_image/requirements.txt (line 1))\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r diffusers/examples/text_to_image/requirements.txt (line 2)) (0.16.0+cu118)\n",
            "Requirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from -r diffusers/examples/text_to_image/requirements.txt (line 3)) (4.35.2)\n",
            "Collecting datasets (from -r diffusers/examples/text_to_image/requirements.txt (line 4))\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy (from -r diffusers/examples/text_to_image/requirements.txt (line 5))\n",
            "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r diffusers/examples/text_to_image/requirements.txt (line 6)) (2.14.1)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.10/dist-packages (from -r diffusers/examples/text_to_image/requirements.txt (line 7)) (3.1.2)\n",
            "Collecting peft==0.7.0 (from -r diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Downloading peft-0.7.0-py3-none-any.whl (168 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (4.66.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (0.4.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (0.19.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->-r diffusers/examples/text_to_image/requirements.txt (line 2)) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r diffusers/examples/text_to_image/requirements.txt (line 2)) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (3.2.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r diffusers/examples/text_to_image/requirements.txt (line 3)) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r diffusers/examples/text_to_image/requirements.txt (line 3)) (0.15.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (9.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets->-r diffusers/examples/text_to_image/requirements.txt (line 4))\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets->-r diffusers/examples/text_to_image/requirements.txt (line 4))\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (3.4.1)\n",
            "Collecting multiprocess (from datasets->-r diffusers/examples/text_to_image/requirements.txt (line 4))\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (3.9.1)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->-r diffusers/examples/text_to_image/requirements.txt (line 5)) (0.2.12)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (1.59.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (3.5.1)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (3.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2->-r diffusers/examples/text_to_image/requirements.txt (line 7)) (2.1.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (4.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r diffusers/examples/text_to_image/requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r diffusers/examples/text_to_image/requirements.txt (line 2)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r diffusers/examples/text_to_image/requirements.txt (line 2)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r diffusers/examples/text_to_image/requirements.txt (line 2)) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (2023.3.post1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (3.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (1.3.0)\n",
            "Installing collected packages: pyarrow-hotfix, ftfy, dill, multiprocess, accelerate, datasets, peft\n",
            "Successfully installed accelerate-0.25.0 datasets-2.15.0 dill-0.3.7 ftfy-6.1.3 multiprocess-0.70.15 peft-0.7.0 pyarrow-hotfix-0.6\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.16.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.38.0-py2.py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/252.8 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.40 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.38.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0aMSUIrFWq9"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate\n",
        "\n",
        "!accelerate env"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ln -s /content/drive/MyDrive/colab/ldn ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JDGxQsXSyzI",
        "outputId": "3cdb06a7-8446-4236-aa3c-df995dc3f95f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ln: failed to create symbolic link './ldn': File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate config"
      ],
      "metadata": {
        "id": "TWeK2lCvS0rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Новый раздел"
      ],
      "metadata": {
        "id": "ez4Fc-6q47l3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILtWz_d26LUH"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import normalize\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet50\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "from transformers import AutoImageProcessor, AutoModel\n",
        "from diffusers import StableDiffusionXLPipeline\n",
        "\n",
        "import torchvision\n",
        "import pathlib\n",
        "from tqdm import tqdm\n",
        "\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "\n",
        "\n",
        "cuda_flag = True\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "def generate_images_with_prompt(prompt, output_dir, num_images=10, image_size=(256, 256), image_mode='RGB'):\n",
        "\n",
        "    # Check if the destination directory exists, and create it if not\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    else:\n",
        "        # Empty the destination directory if it's not already empty\n",
        "        for file_name in os.listdir(output_dir):\n",
        "            file_path = os.path.join(output_dir, file_name)\n",
        "            try:\n",
        "                if os.path.isfile(file_path):\n",
        "                    os.unlink(file_path)\n",
        "            except Exception as e:\n",
        "                print(f\"Error deleting {file_path}: {e}\")\n",
        "\n",
        "    for i in range(num_images):\n",
        "        # Generate a random image using the prompt\n",
        "\n",
        "        pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "        \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype = torch.float16\n",
        "        )\n",
        "        if cuda_flag:\n",
        "            pipe = pipe.to(\"cuda\")\n",
        "        # pipe.enable_model_cpu_offload()\n",
        "        image = pipe(prompt).images[0]\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Save the generated image\n",
        "        image_path = os.path.join(output_dir, f\"generated_image_{i}.png\")\n",
        "        image.save(image_path)\n",
        "\n",
        "        print(f\"Generated image saved at: {image_path}\")\n",
        "\n",
        "\n",
        "def write_to_jsonl(directory_path, output_jsonl_path, prompt):\n",
        "    \"\"\"\n",
        "    Open a JSONL file in a directory, clear its contents, and write rows for all files in the directory.\n",
        "\n",
        "    Parameters:\n",
        "        - directory_path (str): Directory path containing files.\n",
        "        - output_jsonl_path (str): Output JSONL file path.\n",
        "\n",
        "    Returns:\n",
        "        - None\n",
        "    \"\"\"\n",
        "    data = []\n",
        "\n",
        "    # Iterate over files in the directory\n",
        "    for file_name in os.listdir(directory_path):\n",
        "        if file_name.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            file_path = os.path.join(directory_path, file_name)\n",
        "\n",
        "            # Add a row to the data list\n",
        "            row = {\"file_name\": file_name, \"text\": prompt}  # Modify \"prompt\" with the actual text\n",
        "            data.append(row)\n",
        "\n",
        "    # jsonl_file_exists = os.path.exists(output_jsonl_path)\n",
        "\n",
        "    # Clear the contents of the existing JSONL file\n",
        "    with open(output_jsonl_path, 'w') as jsonl_file:\n",
        "        jsonl_file.write(\"\")\n",
        "\n",
        "    # Write rows to the JSONL file\n",
        "    with open(output_jsonl_path, 'a') as jsonl_file:\n",
        "        for row in data:\n",
        "            jsonl_file.write(json.dumps(row) + '\\n')\n",
        "\n",
        "    print(\"Metadata file is generated\")\n",
        "\n",
        "\n",
        "def generate_tunned_images(prompt, loras_dir, output_dir, num_images=10, image_size=(256, 256)):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for i in range(num_images):\n",
        "        # Generate a random image using the prompt\n",
        "        pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "            \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float32\n",
        "        )\n",
        "        if cuda_flag:\n",
        "            pipe = pipe.to(\"cuda\")\n",
        "        pipe.enable_model_cpu_offload()\n",
        "\n",
        "        for l in loras_dir:\n",
        "            pipe.load_lora_weights(l,\n",
        "                                weight_name=\"pytorch_lora_weights.safetensors\",\n",
        "                                adapter_name=\"lora1\")\n",
        "\n",
        "        # pipeline.set_adapters([\"ikea\", \"cereal\"], adapter_weights=[0.7, 0.5])\n",
        "\n",
        "        # pipe.load_textual_inversion(\"sd-concepts-library/cat-toy\")\n",
        "        # prompt = \"A <cat-toy> backpack\"\n",
        "\n",
        "        # pipe.load_textual_inversion(\"./charturnerv2.pt\", token=\"charturnerv2\")\n",
        "        # prompt = \"charturnerv2, multiple views of the same character in the same outfit, a character turnaround of a woman wearing a black jacket and red shirt, best quality, intricate details.\"\n",
        "\n",
        "        image = pipe(prompt).images[0]\n",
        "\n",
        "        # Save the generated image\n",
        "        image_path = os.path.join(output_dir, f\"generated_image_{i + 1}.png\")\n",
        "        image.save(image_path)\n",
        "\n",
        "        print(f\"Generated image saved at: {image_path}\")\n",
        "\n",
        "def extract_features(path):\n",
        "    from transformers import AutoImageProcessor, AutoModel\n",
        "    from PIL import Image\n",
        "    import requests\n",
        "\n",
        "    image = Image.open(path)\n",
        "    # image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "    processor = AutoImageProcessor.from_pretrained('facebook/dinov2-small')\n",
        "    model = AutoModel.from_pretrained('facebook/dinov2-small')\n",
        "\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    last_hidden_states = outputs.last_hidden_state\n",
        "    return last_hidden_states\n",
        "\n",
        "def process_images_in_directory(directory, method_function, *args, **kwargs):\n",
        "    \"\"\"\n",
        "    Process all images in the specified directory using the provided method.\n",
        "\n",
        "    Parameters:\n",
        "        - directory (str): Path to the directory containing images.\n",
        "        - method_function (callable): The method/function to run for each image.\n",
        "        - *args, **kwargs: Additional arguments to pass to the method_function.\n",
        "\n",
        "    Returns:\n",
        "        - List: A list containing the results of applying the method to each image.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    # Iterate over all files in the directory\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            # Construct the full path to the image\n",
        "            image_path = os.path.join(directory, filename)\n",
        "\n",
        "            # Run the method for the current image\n",
        "            result = method_function(image_path, *args, **kwargs)\n",
        "            results.append(result)\n",
        "\n",
        "    return results\n",
        "\n",
        "def cluster_embeddings(embeddings, num_clusters, dmin_c):\n",
        "    \"\"\"\n",
        "    Cluster the embeddings of generated images using K-Means++ and filter clusters.\n",
        "\n",
        "    Parameters:\n",
        "        - image_directory (str): Path to the directory containing generated images.\n",
        "        - embeddings_function (callable): Function to extract embeddings from images.\n",
        "        - num_clusters (int): Number of clusters for K-Means++.\n",
        "        - dmin_c (int): Minimum cluster size threshold.\n",
        "\n",
        "    Returns:\n",
        "        - List: List of filtered clusters.\n",
        "\n",
        "    K - MEANS + + removing all clusters whose size is below\n",
        "    a pre - defined threshold dmin - c\n",
        "\n",
        "    Among the remaining clusters, we\n",
        "    choose the most cohesive\n",
        "\n",
        "    define the cohesion\n",
        "    as the average distance between the members\n",
        "    of c and its centroid ccen\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert embeddings list to numpy array\n",
        "    embeddings = np.array(embeddings)\n",
        "\n",
        "    # Normalize embeddings\n",
        "    embeddings_normalized = normalize(embeddings)\n",
        "\n",
        "    # Perform K-Means++ clustering\n",
        "    kmeans = KMeans(n_clusters=num_clusters, init='k-means++', random_state=42)\n",
        "    cluster_labels = kmeans.fit_predict(embeddings_normalized)\n",
        "\n",
        "    # Calculate cosine similarity matrix\n",
        "    cosine_sim_matrix = cosine_similarity(embeddings_normalized)\n",
        "\n",
        "    # Initialize filtered clusters\n",
        "    filtered_clusters = []\n",
        "\n",
        "    # Iterate over unique cluster labels\n",
        "    for cluster_label in np.unique(cluster_labels):\n",
        "        # Find indices of images belonging to the current cluster\n",
        "        cluster_indices = np.where(cluster_labels == cluster_label)[0]\n",
        "\n",
        "        # Calculate the average cosine similarity within the cluster\n",
        "        #TODO: switch to cohession\n",
        "        avg_similarity = np.mean(cosine_sim_matrix[cluster_indices][:, cluster_indices])\n",
        "\n",
        "        # Filter clusters based on the minimum size threshold and average similarity\n",
        "        if len(cluster_indices) >= dmin_c and avg_similarity >= 0.5:  # Adjust similarity threshold as needed\n",
        "            filtered_clusters.append({\n",
        "                'label': cluster_label,\n",
        "                'size': len(cluster_indices),\n",
        "                'cluster': cluster_indices\n",
        "                # ,\n",
        "                # 'image_paths': [image_paths[i] for i in cluster_indices]\n",
        "            })\n",
        "        #TODO: where is cluster\n",
        "\n",
        "    return filtered_clusters\n",
        "\n",
        "def copy_selected_files(src_directory, dest_directory, selected_file_ids, selected_file_extensions):\n",
        "    \"\"\"\n",
        "    Copy selected files from the source directory to the destination directory.\n",
        "\n",
        "    Parameters:\n",
        "        - src_directory (str): Source directory path.\n",
        "        - dest_directory (str): Destination directory path.\n",
        "        - selected_file_ids (list): List of file IDs to copy.\n",
        "        - selected_file_extensions (list): List of file extensions to copy.\n",
        "\n",
        "    Returns:\n",
        "        - None\n",
        "    \"\"\"\n",
        "    # Check if the destination directory exists, and create it if not\n",
        "    if not os.path.exists(dest_directory):\n",
        "        os.makedirs(dest_directory)\n",
        "    else:\n",
        "        # Empty the destination directory if it's not already empty\n",
        "        for file_name in os.listdir(dest_directory):\n",
        "            file_path = os.path.join(dest_directory, file_name)\n",
        "            try:\n",
        "                if os.path.isfile(file_path):\n",
        "                    os.unlink(file_path)\n",
        "            except Exception as e:\n",
        "                print(f\"Error deleting {file_path}: {e}\")\n",
        "\n",
        "    # Iterate over files in the source directory\n",
        "    for file_name in os.listdir(src_directory):\n",
        "        src_file_path = os.path.join(src_directory, file_name)\n",
        "\n",
        "        # Check if the file has the desired extension and is in the selected IDs\n",
        "        _, file_extension = os.path.splitext(file_name)\n",
        "\n",
        "        if file_extension.lower() in selected_file_extensions \\\n",
        "            and file_name in selected_file_ids:\n",
        "            dest_file_path = os.path.join(dest_directory, file_name)\n",
        "\n",
        "            # Copy the selected file to the destination directory\n",
        "            shutil.copy2(src_file_path, dest_file_path)\n",
        "\n",
        "            print(f\"File copied: {file_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !export MODEL_NAME=\"runwayml/stable-diffusion-v1-5\"\n",
        "# !export OUTPUT_DIR=\"test_lora\"\n",
        "# !export HUB_MODEL_ID=\"vel58/stable_character\"\n",
        "# # generated_images/lora_dataset\n",
        "# !export DATASET_NAME=\"/content/drive/MyDrive/generated_images\"\n",
        "\n",
        "# # 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\n",
        "\n",
        "\n",
        "# # accelerate launch --mixed_precision=\"fp16\"\n",
        "# !accelerate launch --mixed_precision=\"fp16\" python diffusers/examples/text_to_image/train_text_to_image_lora.py \\\n",
        "#   --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
        "#   --train_data_dir=\"/content/drive/MyDrive/generated_images\" \\\n",
        "#   --rank=1\\\n",
        "#   --dataloader_num_workers=8 \\\n",
        "#   --resolution=256 \\\n",
        "#   --center_crop \\\n",
        "#   --random_flip \\\n",
        "#   --train_batch_size=2 \\\n",
        "#   --gradient_accumulation_steps=4 \\\n",
        "#   --max_train_steps=1500 \\\n",
        "#   --learning_rate=1e-02 \\\n",
        "#   --max_grad_norm=1 \\\n",
        "#   --lr_scheduler=\"cosine\" \\\n",
        "#   --lr_warmup_steps=0 \\\n",
        "#   --output_dir=\"test_lora\" \\\n",
        "#   --report_to=wandb \\\n",
        "#   --checkpointing_steps=500 \\\n",
        "#   --validation_prompt=\"beautiful woman wearing glasses in the style of naïve drawing,in the style of quick drawing\" \\\n",
        "#   --seed=1337\n",
        "\n",
        "#   #   # --push_to_hub \\\n",
        "#   # --hub_model_id=\"vel58/stable_character\" \\\n",
        "#   # --hub_token"
      ],
      "metadata": {
        "id": "_YBHdBt1ZmZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "def calculate_average_distance(embeddings):\n",
        "    \"\"\"\n",
        "    Calculate the average pairwise Euclidean distance between embeddings.\n",
        "\n",
        "    Parameters:\n",
        "        - embeddings (np.ndarray): Array of shape (N, D) containing N embeddings of dimension D.\n",
        "\n",
        "    Returns:\n",
        "        - float: The average pairwise Euclidean distance.\n",
        "    \"\"\"\n",
        "    try:\n",
        "      embeddings=[e.detach().numpy() for e in embeddings]\n",
        "    except:\n",
        "      pass\n",
        "    embeddings = np.array(embeddings).reshape(len(embeddings), -1)\n",
        "\n",
        "    pairwise_distances = squareform(pdist(embeddings, metric='euclidean'))\n",
        "    average_distance = np.mean(pairwise_distances)\n",
        "    return average_distance\n",
        "\n",
        "def cluster_engine(filtered_clusters, embeddings):\n",
        "    min_distance = 0\n",
        "    final_cluster_n = 0\n",
        "    for c in range(len(filtered_clusters)):\n",
        "        selected_cluster = [embeddings[i] for i in filtered_clusters[c]['cluster']]\n",
        "        dis = calculate_average_distance(selected_cluster)\n",
        "        print(f'cluster: {c}, distance: {dis}')\n",
        "        if dis>0 and dis < min_distance:\n",
        "          min_distance=dis\n",
        "          final_cluster_n = c\n",
        "        elif min_distance==0 and dis>min_distance:\n",
        "          min_distance=dis\n",
        "          final_cluster_n = c\n",
        "    return filtered_clusters[final_cluster_n]\n",
        "\n",
        "\n",
        "def identity_extraction(dataset_directory, output_directory):\n",
        "    return\n",
        "\n",
        "\n",
        "def engine(dataset_directory, output_directory):\n",
        "    # Extract features from images\n",
        "    embeddings = process_images_in_directory(dataset_directory, extract_features)\n",
        "\n",
        "    embeddings=[e.detach().numpy() for e in embeddings]\n",
        "    print(np.array(embeddings).shape)\n",
        "    embeddings = np.array(embeddings).reshape(len(embeddings), -1)\n",
        "\n",
        "    # Run KMEANS and filter clusters\n",
        "    filtered_clusters = cluster_embeddings(embeddings, num_clusters=5, dmin_c=2)\n",
        "\n",
        "    print(f'Filtered clusters: {filtered_clusters}')\n",
        "\n",
        "    # Take the most coherent cluster\n",
        "    final_cluster = cluster_engine(filtered_clusters, embeddings)\n",
        "\n",
        "    final_cluster_imgs = final_cluster['cluster']\n",
        "    print(f'Selected cluster: {final_cluster}')\n",
        "    print(f'Selected images: {final_cluster_imgs}')\n",
        "\n",
        "    # Copy selected images into separate folder\n",
        "\n",
        "    selected_file_ids = [f'generated_image_{i}.png' for i in final_cluster_imgs]  # Mention the IDs of the files you want to copy\n",
        "    selected_extensions = ['.png', '.jpg']\n",
        "\n",
        "    copy_selected_files(dataset_directory, output_directory, selected_file_ids, selected_extensions)\n",
        "\n",
        "    # Train LORA\n",
        "    identity_extraction(output_directory=output_directory, dataset_directory=dataset_directory)\n",
        "    print(f'LORA dataset is saved to: {output_directory}')\n",
        "\n",
        "    return final_cluster\n",
        "\n"
      ],
      "metadata": {
        "id": "WYd9Otmjdz20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"beautiful woman wearing glasses in the style of naïve drawing,\n",
        "in the style of quick drawing, white background --W 256 --H 256\"\"\"\n",
        "\n",
        "base_directory = \"/content/drive/MyDrive/generated_images\"\n",
        "num_images_to_generate = 20\n",
        "\n",
        "average_distance = 200\n",
        "dconv = 150\n",
        "\n",
        "    # Generate and save N images with the same prompt\n",
        "generate_images_with_prompt(prompt, base_directory, num_images_to_generate)\n",
        "write_to_jsonl(base_directory,\n",
        "os.path.join(base_directory, \"metadata.jsonl\"), prompt)\n",
        "\n",
        "\n",
        "# !rm -R generated_images/class/.ipynb_checkpoints\n",
        "# !rm -R generated_images/.ipynb_checkpoints\n",
        "# !ls generated_images/ -a\n",
        "i = 0\n",
        "output_directory = base_directory\n",
        "while average_distance >= dconv:\n",
        "      lora_dataset_dir = os.path.join(output_directory, \"lora_dataset\")\n",
        "      final_cluster = engine(dataset_directory = output_directory,\n",
        "              output_directory = lora_dataset_dir)\n",
        "      write_to_jsonl(lora_dataset_dir,\n",
        "                     os.path.join(lora_dataset_dir, \"metadata.jsonl\"), prompt)\n",
        "      embeddings = process_images_in_directory(lora_dataset_dir, extract_features)\n",
        "\n",
        "      # Recalculate the average pairwise distance\n",
        "      average_distance = calculate_average_distance(embeddings)\n",
        "      print(f'Step {i} average distance: {average_distance}')\n",
        "\n",
        "      !python diffusers/examples/text_to_image/train_text_to_image_lora.py \\\n",
        "        --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
        "        --train_data_dir=\"/content/drive/MyDrive/generated_images\" \\\n",
        "        --rank=1\\\n",
        "        --dataloader_num_workers=8 \\\n",
        "        --resolution=256 \\\n",
        "        --center_crop \\\n",
        "        --random_flip \\\n",
        "        --train_batch_size=2 \\\n",
        "        --gradient_accumulation_steps=4 \\\n",
        "        --max_train_steps=1500 \\\n",
        "        --learning_rate=1e-02 \\\n",
        "        --max_grad_norm=1 \\\n",
        "        --lr_scheduler=\"cosine\" \\\n",
        "        --lr_warmup_steps=0 \\\n",
        "        --output_dir=\"/content/drive/MyDrive/loras\" \\\n",
        "        --checkpointing_steps=500 \\\n",
        "        --validation_prompt=\"beautiful woman wearing glasses in the style of naïve drawing,in the style of quick drawing\" \\\n",
        "        --seed=1337\n",
        "\n",
        "        # --report_to=wandb \\\n",
        "\n",
        "      # Generate new set of images with LORA\n",
        "      output_directory=os.path.join(base_directory, f'_step{i}')\n",
        "\n",
        "      generate_tunned_images(prompt, loras_dir=[\"/content/drive/MyDrive/loras\"],\n",
        "                             output_directory=output_directory,\n",
        "                             num_images=num_images_to_generate)\n",
        "\n",
        "      embeddings = process_images_in_directory(output_directory, extract_features)\n",
        "\n",
        "      # Recalculate the average pairwise distance\n",
        "      average_distance = calculate_average_distance(embeddings)\n",
        "      print(f'Step {i} new sample average distance: {average_distance}')\n",
        "\n",
        "\n",
        "      i+=1\n"
      ],
      "metadata": {
        "id": "PBtrTEtBb48v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings)"
      ],
      "metadata": {
        "id": "Y9rlkaxrfFUZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06138d1d-4851-4937-bd10-97a26ce65564"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b6zyK78TZdhS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "mount_file_id": "18PzorarblmH7WgZ-VG_AIU3FMA1njdEX",
      "authorship_tag": "ABX9TyMw2FEDvLE+2tK4krA8Dvjz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
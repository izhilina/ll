{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/izhilina/ll/blob/master/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9UgHnAi6cZq"
      },
      "outputs": [],
      "source": [
        "!pip install diffusers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/accelerate.git"
      ],
      "metadata": {
        "id": "JHbUEJkU05H2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0aMSUIrFWq9"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate\n",
        "!accelerate config default\n",
        "!accelerate env"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Новый раздел"
      ],
      "metadata": {
        "id": "ez4Fc-6q47l3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILtWz_d26LUH"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import normalize\n",
        "import os\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet50\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "from transformers import AutoImageProcessor, AutoModel\n",
        "from diffusers import StableDiffusionXLPipeline\n",
        "\n",
        "import torchvision\n",
        "import pathlib\n",
        "from tqdm import tqdm\n",
        "\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "\n",
        "\n",
        "cuda_flag = True\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "def generate_images_with_prompt(prompt, output_dir, num_images=10, image_size=(256, 256), image_mode='RGB'):\n",
        "    # Create the output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for i in range(num_images):\n",
        "        # Generate a random image using the prompt\n",
        "\n",
        "        pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "        \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype = torch.float16\n",
        "        )\n",
        "        if cuda_flag:\n",
        "            pipe = pipe.to(\"cuda\")\n",
        "        # pipe.enable_model_cpu_offload()\n",
        "        image = pipe(prompt).images[0]\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Save the generated image\n",
        "        image_path = os.path.join(output_dir, f\"generated_image_{i}.png\")\n",
        "        image.save(image_path)\n",
        "\n",
        "        print(f\"Generated image saved at: {image_path}\")\n",
        "\n",
        "def extract_features(path):\n",
        "    from transformers import AutoImageProcessor, AutoModel\n",
        "    from PIL import Image\n",
        "    import requests\n",
        "\n",
        "    image = Image.open(path)\n",
        "    # image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "    processor = AutoImageProcessor.from_pretrained('facebook/dinov2-small')\n",
        "    model = AutoModel.from_pretrained('facebook/dinov2-small')\n",
        "\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    last_hidden_states = outputs.last_hidden_state\n",
        "    return last_hidden_states\n",
        "\n",
        "def process_images_in_directory(directory, method_function, *args, **kwargs):\n",
        "    \"\"\"\n",
        "    Process all images in the specified directory using the provided method.\n",
        "\n",
        "    Parameters:\n",
        "        - directory (str): Path to the directory containing images.\n",
        "        - method_function (callable): The method/function to run for each image.\n",
        "        - *args, **kwargs: Additional arguments to pass to the method_function.\n",
        "\n",
        "    Returns:\n",
        "        - List: A list containing the results of applying the method to each image.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    # Iterate over all files in the directory\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            # Construct the full path to the image\n",
        "            image_path = os.path.join(directory, filename)\n",
        "\n",
        "            # Run the method for the current image\n",
        "            result = method_function(image_path, *args, **kwargs)\n",
        "            results.append(result)\n",
        "\n",
        "    return results\n",
        "\n",
        "def cluster_embeddings(embeddings, num_clusters, dmin_c):\n",
        "    \"\"\"\n",
        "    Cluster the embeddings of generated images using K-Means++ and filter clusters.\n",
        "\n",
        "    Parameters:\n",
        "        - image_directory (str): Path to the directory containing generated images.\n",
        "        - embeddings_function (callable): Function to extract embeddings from images.\n",
        "        - num_clusters (int): Number of clusters for K-Means++.\n",
        "        - dmin_c (int): Minimum cluster size threshold.\n",
        "\n",
        "    Returns:\n",
        "        - List: List of filtered clusters.\n",
        "\n",
        "    K - MEANS + + removing all clusters whose size is below\n",
        "    a pre - defined threshold dmin - c\n",
        "\n",
        "    Among the remaining clusters, we\n",
        "    choose the most cohesive\n",
        "\n",
        "    define the cohesion\n",
        "    as the average distance between the members\n",
        "    of c and its centroid ccen\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert embeddings list to numpy array\n",
        "    embeddings = np.array(embeddings)\n",
        "\n",
        "    # Normalize embeddings\n",
        "    embeddings_normalized = normalize(embeddings)\n",
        "\n",
        "    # Perform K-Means++ clustering\n",
        "    kmeans = KMeans(n_clusters=num_clusters, init='k-means++', random_state=42)\n",
        "    cluster_labels = kmeans.fit_predict(embeddings_normalized)\n",
        "\n",
        "    # Calculate cosine similarity matrix\n",
        "    cosine_sim_matrix = cosine_similarity(embeddings_normalized)\n",
        "\n",
        "    # Initialize filtered clusters\n",
        "    filtered_clusters = []\n",
        "\n",
        "    # Iterate over unique cluster labels\n",
        "    for cluster_label in np.unique(cluster_labels):\n",
        "        # Find indices of images belonging to the current cluster\n",
        "        cluster_indices = np.where(cluster_labels == cluster_label)[0]\n",
        "\n",
        "        # Calculate the average cosine similarity within the cluster\n",
        "        #TODO: switch to cohession\n",
        "        avg_similarity = np.mean(cosine_sim_matrix[cluster_indices][:, cluster_indices])\n",
        "\n",
        "        # Filter clusters based on the minimum size threshold and average similarity\n",
        "        if len(cluster_indices) >= dmin_c and avg_similarity >= 0.5:  # Adjust similarity threshold as needed\n",
        "            filtered_clusters.append({\n",
        "                'label': cluster_label,\n",
        "                'size': len(cluster_indices),\n",
        "                'cluster': cluster_indices\n",
        "                # ,\n",
        "                # 'image_paths': [image_paths[i] for i in cluster_indices]\n",
        "            })\n",
        "        #TODO: where is cluster\n",
        "\n",
        "    return filtered_clusters\n",
        "\n",
        "\n",
        "def calculate_average_distance(embeddings):\n",
        "    \"\"\"\n",
        "    Calculate the average pairwise Euclidean distance between embeddings.\n",
        "\n",
        "    Parameters:\n",
        "        - embeddings (np.ndarray): Array of shape (N, D) containing N embeddings of dimension D.\n",
        "\n",
        "    Returns:\n",
        "        - float: The average pairwise Euclidean distance.\n",
        "    \"\"\"\n",
        "    pairwise_distances = squareform(pdist(embeddings, metric='euclidean'))\n",
        "    average_distance = np.mean(pairwise_distances)\n",
        "    return average_distance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def copy_selected_files(src_directory, dest_directory, selected_file_ids, selected_file_extensions):\n",
        "    \"\"\"\n",
        "    Copy selected files from the source directory to the destination directory.\n",
        "\n",
        "    Parameters:\n",
        "        - src_directory (str): Source directory path.\n",
        "        - dest_directory (str): Destination directory path.\n",
        "        - selected_file_ids (list): List of file IDs to copy.\n",
        "        - selected_file_extensions (list): List of file extensions to copy.\n",
        "\n",
        "    Returns:\n",
        "        - None\n",
        "    \"\"\"\n",
        "    # Check if the destination directory exists, and create it if not\n",
        "    if not os.path.exists(dest_directory):\n",
        "        os.makedirs(dest_directory)\n",
        "    else:\n",
        "        # Empty the destination directory if it's not already empty\n",
        "        for file_name in os.listdir(dest_directory):\n",
        "            file_path = os.path.join(dest_directory, file_name)\n",
        "            try:\n",
        "                if os.path.isfile(file_path):\n",
        "                    os.unlink(file_path)\n",
        "            except Exception as e:\n",
        "                print(f\"Error deleting {file_path}: {e}\")\n",
        "\n",
        "    # Iterate over files in the source directory\n",
        "    for file_name in os.listdir(src_directory):\n",
        "        src_file_path = os.path.join(src_directory, file_name)\n",
        "\n",
        "        print(src_file_path)\n",
        "\n",
        "        # Check if the file has the desired extension and is in the selected IDs\n",
        "        _, file_extension = os.path.splitext(file_name)\n",
        "\n",
        "        if file_extension.lower() in selected_file_extensions \\\n",
        "            and file_name in selected_file_ids:\n",
        "            dest_file_path = os.path.join(dest_directory, file_name)\n",
        "\n",
        "            # Copy the selected file to the destination directory\n",
        "            shutil.copy2(src_file_path, dest_file_path)\n",
        "\n",
        "            print(f\"File copied: {file_name}\")\n"
      ],
      "metadata": {
        "id": "WYd9Otmjdz20"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/huggingface/diffusers\n",
        "!cd diffusers\n",
        "!pip install -r diffusers/examples/text_to_image/requirements.txt"
      ],
      "metadata": {
        "id": "pe_vroIviWru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt = \"beautiful woman wearing glasses in the style of naïve drawing, in the style of quick drawing --W 256 --H 256\"\n",
        "\n",
        "#     # Set the output directory\n",
        "# output_directory = \"generated_images\"\n",
        "\n",
        "#     # Set the number of images to generate\n",
        "# num_images_to_generate = 10\n",
        "\n",
        "#     # Generate and save N images with the same prompt\n",
        "# generate_images_with_prompt(prompt, output_directory, num_images_to_generate)\n",
        "\n",
        "\n",
        "# # !rm -R generated_images/class/.ipynb_checkpoints\n",
        "# # !rm -R generated_images/.ipynb_checkpoints\n",
        "# # !ls generated_images/ -a\n",
        "\n",
        "# embeddings = process_images_in_directory(output_directory, extract_features)\n",
        "\n",
        "# embeddings=[e.detach().numpy() for e in embeddings]\n",
        "# print(np.array(embeddings).shape)\n",
        "# embeddings = np.array(embeddings).reshape(10, -1)\n",
        "\n",
        "# filtered_clusters = cluster_embeddings(embeddings, num_clusters=5, dmin_c=2)\n",
        "\n",
        "# print(f'Filtered clusters: {filtered_clusters}')\n",
        "\n",
        "# min_distance = 0\n",
        "# final_cluster_n = 0\n",
        "# for c in range(len(filtered_clusters)):\n",
        "#     selected_cluster = [embeddings[i] for i in filtered_clusters[c]['cluster']]\n",
        "#     dis = calculate_average_distance(np.array(selected_cluster).reshape(len(selected_cluster), -1))\n",
        "#     print(f'cluster: {c}, distance: {dis}')\n",
        "#     if dis>0 and dis < min_distance:\n",
        "#       min_distance=dis\n",
        "#       final_cluster_n = c\n",
        "#     elif min_distance==0 and dis>min_distance:\n",
        "#       min_distance=dis\n",
        "#       final_cluster_n = c\n",
        "\n",
        "# print(f'Selected cluster: {final_cluster_n}')\n",
        "\n",
        "# final_cluster_imgs = filtered_clusters[final_cluster_n]['cluster']\n",
        "\n",
        "print(f'Selected images: {final_cluster_imgs}')\n",
        "\n",
        "destination_directory = os.path.join(output_directory, \"lora_dataset\")\n",
        "selected_file_ids = [f'generated_image_{i}.png' for i in final_cluster_imgs]  # Mention the IDs of the files you want to copy\n",
        "selected_extensions = ['.png', '.jpg']\n",
        "\n",
        "copy_selected_files(output_directory, destination_directory, selected_file_ids, selected_extensions)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBtrTEtBb48v",
        "outputId": "9b3f1cf3-4bad-420b-d2bc-2cc15cf6d11e"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected images: [2 3 6]\n",
            "generated_images/generated_image_2.png\n",
            "File copied: generated_image_2.png\n",
            "generated_images/generated_image_7.png\n",
            "generated_images/generated_image_10.png\n",
            "generated_images/generated_image_8.png\n",
            "generated_images/lora_dataset\n",
            "generated_images/generated_image_1.png\n",
            "generated_images/generated_image_5.png\n",
            "generated_images/generated_image_9.png\n",
            "generated_images/generated_image_6.png\n",
            "File copied: generated_image_6.png\n",
            "generated_images/generated_image_4.png\n",
            "generated_images/generated_image_3.png\n",
            "File copied: generated_image_3.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y9rlkaxrfFUZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "18PzorarblmH7WgZ-VG_AIU3FMA1njdEX",
      "authorship_tag": "ABX9TyOthvxL6+r1CcSD3xrKrq5o",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}